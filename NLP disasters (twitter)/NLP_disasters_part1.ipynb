{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8hwaaTCJDmsa"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmQxXcpKDmsd"
      },
      "source": [
        "# First approach - CountVectorizer (model: Lineal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIAYQ_tUDmsf",
        "outputId": "67e99998-e347-4068-ccf9-c4456bdb673d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7613, 5)\n",
            "(3263, 4)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K65ywyeEDmsg"
      },
      "outputs": [],
      "source": [
        "#What CountVectorizer does is to create a \"vocabulary list\" with all the words used in all the given data (all the words of all sencente: twitts) in this case it makes \n",
        "# a total of 21637 words. Afterwards the function compares this vocabulary list with every sentence and set 1 when the word of the sentence appears in the vocabulary\n",
        "# list (it can be 2 if the word appear twice and so on). This means we will have for every sentence a lenth of 21637."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9HsPkUaDmsh"
      },
      "outputs": [],
      "source": [
        "count_vectorizer = feature_extraction.text.CountVectorizer()\n",
        "\n",
        "## let's get counts for the first 5 tweets in the data\n",
        "example_train_vectors = count_vectorizer.fit_transform(train_df[\"text\"][0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yoykzql0Dmsh",
        "outputId": "7111567e-4d4d-42f0-a5af-e8084f4c3679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this is the first sentence:   Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all\n",
            "\n",
            "these are the dimensions of the vector of the first sentence:  (1, 54)\n",
            "\n",
            "this is the vector for the first sentence: \n",
            " [[0 0 0 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 0\n",
            "  0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 1 0]]\n",
            "\n",
            "this is the vocabulary list for the 5 first sentences (same dimensions that vector): \n",
            " {'our': 34, 'deeds': 12, 'are': 5, 'the': 49, 'reason': 39, 'of': 29, 'this': 50, 'earthquake': 13, 'may': 25, 'allah': 4, 'forgive': 18, 'us': 52, 'all': 3, 'forest': 17, 'fire': 16, 'near': 26, 'la': 24, 'ronge': 42, 'sask': 44, 'canada': 11, 'residents': 41, 'asked': 7, 'to': 51, 'shelter': 47, 'in': 21, 'place': 37, 'being': 8, 'notified': 28, 'by': 9, 'officers': 30, 'no': 27, 'other': 33, 'evacuation': 14, 'or': 31, 'orders': 32, 'expected': 15, '13': 1, '000': 0, 'people': 35, 'receive': 40, 'wildfires': 53, 'california': 10, 'just': 23, 'got': 20, 'sent': 46, 'photo': 36, 'from': 19, 'ruby': 43, 'alaska': 2, 'as': 6, 'smoke': 48, 'pours': 38, 'into': 22, 'school': 45}\n"
          ]
        }
      ],
      "source": [
        "#we use .todense() here because these vectors are \"sparse\" (only non-zero elements are kept to save space)\n",
        "print('this is the first sentence:  ',train_df[\"text\"][0])\n",
        "print('\\nthese are the dimensions of the vector of the first sentence: ',example_train_vectors[0].todense().shape)\n",
        "print('\\nthis is the vector for the first sentence: \\n',example_train_vectors[0].todense())\n",
        "print('\\nthis is the vocabulary list for the 5 first sentences (same dimensions that vector): \\n',count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N98t1VNbDmsi"
      },
      "outputs": [],
      "source": [
        "train_vectors = count_vectorizer.fit_transform(train_df[\"text\"])\n",
        "\n",
        "## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n",
        "# that the tokens in the train vectors are the only ones mapped to the test vectors - \n",
        "# i.e. that the train and test vectors use the same set of tokens.\n",
        "test_vectors = count_vectorizer.transform(test_df[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BM2mLdCDmsi",
        "outputId": "ae6775cd-080a-46c1-c2f6-ff8e16205b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7613, 21637)\n",
            "(3263, 21637)\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors.todense().shape)\n",
        "print(test_vectors.todense().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_U59jwrpDmsj",
        "outputId": "d9571495-aeb5-4761-953e-ba77ff2be421"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1, 21637)\n",
            "[[0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors[0].todense().shape)\n",
        "print(train_vectors[0].todense())\n",
        "#print('\\nthis is the vocabulary list all sentences (same dimensions that vector): \\n',count_vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdiFX9zLDmsj",
        "outputId": "af4300c9-5a5f-41ca-d6b8-d8e57e24ea0a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3263, 21637)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vectorizer.transform(test_df[\"text\"]).todense().shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38Rn7QDADmsj"
      },
      "outputs": [],
      "source": [
        "## Our vectors are really big, so we want to push our model's weights\n",
        "## toward 0 without completely discounting different words - ridge regression \n",
        "## is a good way to do this.\n",
        "clf = linear_model.RidgeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOnKc2QzDmsk",
        "outputId": "cd711e59-01d0-4a76-f24c-bcefdfa6e73a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7613, 21637)\n",
            "(7613,)\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors.shape)\n",
        "print(train_df[\"target\"].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3B59dArlDmsk",
        "outputId": "081ef4fb-3340-4cf8-cd66-5ef0dc641831"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.59453669, 0.56455572, 0.64082434])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWKh2gjdDmsk",
        "outputId": "18bae7c9-1f2c-431c-c606-814c078a1085"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RidgeClassifier()"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(train_vectors, train_df[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kH_BIc7MDmsl"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNEAgQbADmsl"
      },
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = clf.predict(test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLJnyPnqDmsl",
        "outputId": "8fa0a251-a1f0-4482-886b-2ba85525eee7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       0\n",
              "1       1\n",
              "2       1\n",
              "3       0\n",
              "4       1\n",
              "       ..\n",
              "3258    1\n",
              "3259    1\n",
              "3260    1\n",
              "3261    1\n",
              "3262    0\n",
              "Name: target, Length: 3263, dtype: int64"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission[\"target\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7ZcZSBGDmsl"
      },
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_CV.csv\",index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_ZSq4EeDmsm",
        "outputId": "524e308f-f701-4646-e5a7-12193db52336"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aI-MdZveDmsm"
      },
      "source": [
        "# Second approach - TF-IDF (model: Lineal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilVvXAxZDmsm"
      },
      "outputs": [],
      "source": [
        "# What TF-IDF does is to create a \"vocabulary vector\" with all the words used in all the given data (all the words of all sencente: twitts) in this case it makes \n",
        "# a total of 21637 words. Afterwards the function compares this \"vocabulary vector\" with every sentence and set a number of importance (IDF value)\n",
        "# to every word of the \"vocabulary vector\" in the respect of the analysed sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLmr5dC0Dmsm",
        "outputId": "7f3f5431-b297-4156-ee6f-85e7d586b5fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7613, 5)\n",
            "(3263, 4)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mN9qH8itDmsm",
        "outputId": "db0aa8e8-177d-4e32-d5f9-cad598f244d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_vectors:  (7613, 21637)\n",
            "test_vectors:  (3263, 21637)\n"
          ]
        }
      ],
      "source": [
        "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
        "train_vectors = tfIdfVectorizer.fit_transform(train_df[\"text\"])\n",
        "print('train_vectors: ',train_vectors.shape)\n",
        "test_vectors = tfIdfVectorizer.transform(test_df[\"text\"])\n",
        "print('test_vectors: ',test_vectors.shape)\n",
        "#a=tfIdf[0].todense()\n",
        "#print(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh9_bZieDmsn"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbl82VYXDmsn"
      },
      "source": [
        "##### Linear model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psrVThixDmsn"
      },
      "outputs": [],
      "source": [
        "clf = linear_model.RidgeClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsRSMgISDmsn",
        "outputId": "ead34649-7f76-4e5b-8e2c-c5b135a04dd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.63366337, 0.6122449 , 0.68442211])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores = model_selection.cross_val_score(clf, train_vectors, train_df[\"target\"], cv=3, scoring=\"f1\")\n",
        "scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRcbi4jgDmsn",
        "outputId": "a393cc9d-1530-4c8a-e5b9-f17733c5a4ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RidgeClassifier()"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.fit(train_vectors, train_df[\"target\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HT3bwiz3Dmsn"
      },
      "outputs": [],
      "source": [
        "sample_submission = pd.read_csv(\"sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll2hZ4tXDmsn"
      },
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = clf.predict(test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MD9AyNN3Dmsn",
        "outputId": "bc6b811b-d0f0-4a02-b132-472f8c56de33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
              "       0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
              "       0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
              "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
              "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1,\n",
              "       1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
              "       0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
              "       1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1,\n",
              "       0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0,\n",
              "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1,\n",
              "       0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0,\n",
              "       1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1,\n",
              "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0,\n",
              "       1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
              "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
              "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
              "       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1], dtype=int64)"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.predict(test_vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W733-TkDmsn"
      },
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_TFIDF.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_RB7Nk6Dmso"
      },
      "source": [
        "# Third approach - TF-IDF (model: Searching best model with Lazypredict )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nzRr0l8aDmso"
      },
      "outputs": [],
      "source": [
        "from lazypredict.Supervised import LazyClassifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = pd.DataFrame(train_vectors.todense())\n",
        "y = pd.DataFrame(train_df[\"target\"])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state =123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SqsiG9gDDmso",
        "outputId": "b3cae4d0-b186-4b7a-d63c-c4ba929475f3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 29/29 [2:00:29<00:00, 249.29s/it]  "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                               Accuracy  Balanced Accuracy  ROC AUC  F1 Score  \\\n",
            "Model                                                                           \n",
            "BernoulliNB                        0.81               0.79     0.79      0.80   \n",
            "NearestCentroid                    0.80               0.78     0.78      0.79   \n",
            "LGBMClassifier                     0.79               0.77     0.77      0.79   \n",
            "ExtraTreesClassifier               0.79               0.77     0.77      0.79   \n",
            "XGBClassifier                      0.79               0.76     0.76      0.78   \n",
            "NuSVC                              0.78               0.76     0.76      0.77   \n",
            "PassiveAggressiveClassifier        0.77               0.75     0.75      0.76   \n",
            "Perceptron                         0.77               0.75     0.75      0.76   \n",
            "LogisticRegression                 0.77               0.75     0.75      0.76   \n",
            "LinearSVC                          0.76               0.74     0.74      0.76   \n",
            "RidgeClassifierCV                  0.76               0.74     0.74      0.76   \n",
            "RidgeClassifier                    0.76               0.74     0.74      0.76   \n",
            "LinearDiscriminantAnalysis         0.76               0.74     0.74      0.75   \n",
            "RandomForestClassifier             0.77               0.74     0.74      0.76   \n",
            "SVC                                0.77               0.73     0.73      0.75   \n",
            "BaggingClassifier                  0.76               0.73     0.73      0.75   \n",
            "CalibratedClassifierCV             0.76               0.73     0.73      0.75   \n",
            "AdaBoostClassifier                 0.75               0.72     0.72      0.74   \n",
            "DecisionTreeClassifier             0.72               0.71     0.71      0.72   \n",
            "ExtraTreeClassifier                0.71               0.70     0.70      0.71   \n",
            "GaussianNB                         0.60               0.62     0.62      0.60   \n",
            "SGDClassifier                      0.62               0.55     0.55      0.52   \n",
            "DummyClassifier                    0.53               0.52     0.52      0.53   \n",
            "KNeighborsClassifier               0.59               0.52     0.52      0.46   \n",
            "LabelSpreading                     0.59               0.51     0.51      0.45   \n",
            "LabelPropagation                   0.59               0.51     0.51      0.45   \n",
            "QuadraticDiscriminantAnalysis      0.40               0.43     0.43      0.36   \n",
            "\n",
            "                               Time Taken  \n",
            "Model                                      \n",
            "BernoulliNB                         13.60  \n",
            "NearestCentroid                      7.39  \n",
            "LGBMClassifier                      12.77  \n",
            "ExtraTreesClassifier               218.89  \n",
            "XGBClassifier                      251.12  \n",
            "NuSVC                             1342.96  \n",
            "PassiveAggressiveClassifier         12.92  \n",
            "Perceptron                           9.79  \n",
            "LogisticRegression                  12.36  \n",
            "LinearSVC                          403.22  \n",
            "RidgeClassifierCV                  355.84  \n",
            "RidgeClassifier                     20.55  \n",
            "LinearDiscriminantAnalysis         511.27  \n",
            "RandomForestClassifier              79.01  \n",
            "SVC                               1130.83  \n",
            "BaggingClassifier                  158.26  \n",
            "CalibratedClassifierCV            1791.40  \n",
            "AdaBoostClassifier                 177.97  \n",
            "DecisionTreeClassifier              59.68  \n",
            "ExtraTreeClassifier                 11.31  \n",
            "GaussianNB                           9.82  \n",
            "SGDClassifier                       17.49  \n",
            "DummyClassifier                      8.27  \n",
            "KNeighborsClassifier               440.15  \n",
            "LabelSpreading                      26.37  \n",
            "LabelPropagation                    22.70  \n",
            "QuadraticDiscriminantAnalysis      108.72  \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
        "models,predictions = clf.fit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "print(models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxOQRtbFDmso"
      },
      "source": [
        "##### We have seen that the best model according to lazypredict is BernoulliNB, lets try it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSTgnVupDmso"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB\n",
        "X = pd.DataFrame(train_vectors.todense())\n",
        "y = pd.DataFrame(train_df[\"target\"])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=.2,random_state =123)\n",
        "\n",
        "clf = BernoulliNB()\n",
        "clf.fit(X_train,y_train)\n",
        "test_prediction = clf.predict(X_test)\n",
        "test_realvalues = y_test['target'].to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NzUVUWaRDmso",
        "outputId": "dcf5bec0-2a40-434f-f602-878c7d0e2a41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8082731451083388\n"
          ]
        }
      ],
      "source": [
        "#Now we compare the predicted values with the real values on the test section.\n",
        "result=test_prediction==test_realvalues #this makes a true/false matrix with the succesful/unsuccessful predicted values\n",
        "len(result) # these are all the observation in test\n",
        "np.sum(result)  # these are all the true predicted values \n",
        "accuracy=np.sum(result)/len(result)\n",
        "print(accuracy) # The accuracy should be similar to the obtanied in Lazyclassifier (0.81)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jig-KrITDmso"
      },
      "outputs": [],
      "source": [
        "#Now we will train the model again with the dataset complete not only with the 80% of it\n",
        "X_train = tfIdfVectorizer.fit_transform(train_df[\"text\"])\n",
        "X_test = tfIdfVectorizer.transform(test_df[\"text\"])\n",
        "clf = BernoulliNB()\n",
        "clf.fit(train_vectors.todense(),train_df['target'])\n",
        "\n",
        "\n",
        "# now we will predict the test_df \n",
        "X_test=pd.DataFrame(X_test.todense())\n",
        "test_prediction = clf.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZMoTEeK2Dmso",
        "outputId": "e60da586-97dc-463d-e8e8-58d72908d4b5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpAdWg4RDmso"
      },
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = test_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-qsTjULDmsp",
        "outputId": "20389286-7ad4-467d-f878-f921447f411c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       0\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       1\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hf3KO15Dmsp"
      },
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_TFIDF_BernouilliNB.csv\",index=False)\n",
        "#The result obtained in Kaggle is 0.79528 wich is less than the obtained with the lineal model. (0.80049)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfS9FNa5Dmsp"
      },
      "source": [
        "# Fourth approach -RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o799M_kXDmsp"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU,SimpleRNN\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmTfh7ZWDmsp",
        "outputId": "7b80651d-3117-4148-9ef3-727f8bbed80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7613, 5)\n",
            "(3263, 4)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('/content/train.csv')\n",
        "test_df = pd.read_csv('/content/test.csv')\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNVsVP-FD5_-",
        "outputId": "8305440a-5ab6-457d-e04e-a019a52a3ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.9.0\n",
            "2.9.0\n"
          ]
        }
      ],
      "source": [
        "from tensorflow import keras\n",
        "print(keras.__version__)\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LgYIkCaWDmsp"
      },
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text.values, train_df.target.values, \n",
        "                                                  stratify=train_df.target.values, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.2, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Fbwm1LVcDmsp"
      },
      "outputs": [],
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 35 #the maximum value of words (tokens) in the twitts is 33 that's why we set it to 35\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "test_seq=token.texts_to_sequences(test_df.text.values)\n",
        "\n",
        "#zero pad the sequences\n",
        "xtrain_pad = tf.keras.utils.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = tf.keras.utils.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "test_pad = tf.keras.utils.pad_sequences(test_seq, maxlen=max_len)\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pWAacXolNpzE",
        "outputId": "9143215d-4a49-46c5-ce44-cfb1f97ab7fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 35, 300)           6810300   \n",
            "                                                                 \n",
            " simple_rnn_6 (SimpleRNN)    (None, 100)               40100     \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,850,501\n",
            "Trainable params: 6,850,501\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "CPU times: user 261 ms, sys: 8.8 ms, total: 269 ms\n",
            "Wall time: 236 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# A simpleRNN without any pretrained embeddings and one dense layer\n",
        "model_val = Sequential()\n",
        "model_val.add(Embedding(len(word_index) + 1,\n",
        "                 300,\n",
        "                     input_length=max_len))\n",
        "model_val.add(SimpleRNN(100))\n",
        "model_val.add(Dense(1, activation='sigmoid'))\n",
        "model_val.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    \n",
        "model_val.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXapLoIaNCB4",
        "outputId": "c3bddff5-6340-41f8-eaf2-972e92e09a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "96/96 [==============================] - 14s 134ms/step - loss: 0.5707 - accuracy: 0.7028 - val_loss: 0.4841 - val_accuracy: 0.7827\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 14s 141ms/step - loss: 0.1712 - accuracy: 0.9414 - val_loss: 0.6015 - val_accuracy: 0.7295\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 13s 137ms/step - loss: 0.0624 - accuracy: 0.9826 - val_loss: 0.6401 - val_accuracy: 0.7216\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 15s 156ms/step - loss: 0.0373 - accuracy: 0.9892 - val_loss: 0.6014 - val_accuracy: 0.7748\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 13s 132ms/step - loss: 0.0238 - accuracy: 0.9933 - val_loss: 0.6867 - val_accuracy: 0.7400\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 14s 145ms/step - loss: 0.0178 - accuracy: 0.9939 - val_loss: 0.6893 - val_accuracy: 0.7374\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fccf476cbd0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_val.fit(xtrain_pad, ytrain,validation_data=(xvalid_pad, yvalid), epochs=30 , batch_size=64,callbacks = EarlyStopping(patience=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iAxwqBUPDmsq"
      },
      "outputs": [],
      "source": [
        "def roc_auc(predictions,target):\n",
        "    '''\n",
        "    This methods returns the AUC Score when given the Predictions\n",
        "    and Labels\n",
        "    '''\n",
        "    \n",
        "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeuqIsAAEMNb",
        "outputId": "b8c64f91-2e54-4aa8-fe7d-210211d92aae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 9ms/step\n",
            "Auc: 0.81%\n"
          ]
        }
      ],
      "source": [
        "scores = model.predict(xvalid_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "uW9wDdOZENzi"
      },
      "outputs": [],
      "source": [
        "scores_model = []\n",
        "scores_model.append({'Model': 'SimpleRNN','AUC_Score': roc_auc(scores,yvalid)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEjd_z0tDmsq",
        "outputId": "92c05502-e83b-498a-fc1e-ff0426ca81f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 1s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "#Finally we will predict the test to upload the resuts to kaggle\n",
        "test_predict=model.predict(test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sbixKebDmsq",
        "outputId": "aea8c683-93ef-461b-8fc4-ecda812545f0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3263, 1)"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAr3_p0wDmsq",
        "outputId": "b90e4738-d756-4ed8-d4c4-7736a4390cce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.06758979],\n",
              "       [0.8371589 ],\n",
              "       [0.96197146],\n",
              "       ...,\n",
              "       [0.9950584 ],\n",
              "       [0.9998642 ],\n",
              "       [0.7673651 ]], dtype=float32)"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "R6a1CxEKDmsq"
      },
      "outputs": [],
      "source": [
        "# We adopt the correct format (1 or 0)\n",
        "test_predict_format=[1 if value[0]>0.5 else 0 for value in test_predict]\n",
        "test_predict_format=np.array(test_predict_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MXTFRdADmsq",
        "outputId": "6191d240-acb2-4129-b368-3b314d28135e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yNBJt9a2Dmsq",
        "outputId": "7290632b-e710-4504-878f-3c9b4414c8ec"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b441bf1e-dd44-43e8-a648-112fa3c44480\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b441bf1e-dd44-43e8-a648-112fa3c44480')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b441bf1e-dd44-43e8-a648-112fa3c44480 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b441bf1e-dd44-43e8-a648-112fa3c44480');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "HEiNmFrcDmsq"
      },
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = test_predict_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "5bgb1yI4Dmsq"
      },
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_RNN.csv\",index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bJ36FYM_Dmsr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXbPv3lKVN77"
      },
      "source": [
        "# Fifth approach -LSTM (Using pre-trained model GloVe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "veM0QqQfWJR9"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, GRU,SimpleRNN\n",
        "from keras.layers.core import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\n",
        "from keras.preprocessing import sequence, text\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "from plotly import graph_objs as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itJ7hKiPWMwP",
        "outputId": "5035eb6f-b322-4c03-c15f-97c2411570ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(7613, 5)\n",
            "(3263, 4)\n"
          ]
        }
      ],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')\n",
        "print(train_df.shape)\n",
        "print(test_df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "P9LrjE7OX41F"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2196017it [03:35, 10212.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2196016 word vectors.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# load the GloVe vectors in a dictionary:\n",
        "\n",
        "embeddings_index = {}\n",
        "f = open('glove.840B.300d.txt','r',encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.split(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray([float(val) for val in values[1:]])\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text.values, train_df.target.values, \n",
        "                                                  stratify=train_df.target.values, \n",
        "                                                  random_state=42, \n",
        "                                                  test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 35 #the maximum value of words (tokens) in the twitts is 33 that's why we set it to 35\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "test_seq=token.texts_to_sequences(test_df.text.values)\n",
        "\n",
        "#zero pad the sequences\n",
        "xtrain_pad = tf.keras.utils.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = tf.keras.utils.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "test_pad = tf.keras.utils.pad_sequences(test_seq, maxlen=max_len)\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oJpsj5fhVxa-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 22700/22700 [00:00<00:00, 420400.84it/s]\n"
          ]
        }
      ],
      "source": [
        "# create an embedding matrix for the words we have in the dataset\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
        "for word, i in tqdm(word_index.items()):\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "RTKTWPYsYJAY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 35, 300)           6810300   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               160400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,970,801\n",
            "Trainable params: 160,501\n",
            "Non-trainable params: 6,810,300\n",
            "_________________________________________________________________\n",
            "Wall time: 218 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# A simple LSTM with glove embeddings and one dense layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "             300,\n",
        "             weights=[embedding_matrix],\n",
        "             input_length=max_len,\n",
        "             trainable=False))\n",
        "\n",
        "model.add(LSTM(100, dropout=0.3, recurrent_dropout=0.3))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "bP7G5xOZYMRT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B2A16829D8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B2A16829D8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "95/96 [============================>.] - ETA: 0s - loss: 0.5136 - accuracy: 0.7462WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2A2BA78B8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2A2BA78B8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "96/96 [==============================] - 8s 66ms/step - loss: 0.5133 - accuracy: 0.7465 - val_loss: 0.4234 - val_accuracy: 0.8155\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 7s 71ms/step - loss: 0.4298 - accuracy: 0.8092 - val_loss: 0.4135 - val_accuracy: 0.8162\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 7s 76ms/step - loss: 0.4051 - accuracy: 0.8186 - val_loss: 0.4111 - val_accuracy: 0.8194\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 7s 77ms/step - loss: 0.3883 - accuracy: 0.8291 - val_loss: 0.4255 - val_accuracy: 0.8135\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 7s 78ms/step - loss: 0.3739 - accuracy: 0.8355 - val_loss: 0.4113 - val_accuracy: 0.8273\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 8s 80ms/step - loss: 0.3556 - accuracy: 0.8458 - val_loss: 0.4048 - val_accuracy: 0.8299\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 8s 80ms/step - loss: 0.3368 - accuracy: 0.8562 - val_loss: 0.4233 - val_accuracy: 0.8352\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 8s 84ms/step - loss: 0.3233 - accuracy: 0.8609 - val_loss: 0.4357 - val_accuracy: 0.8319\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 8s 83ms/step - loss: 0.3051 - accuracy: 0.8709 - val_loss: 0.4686 - val_accuracy: 0.8247\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 8s 82ms/step - loss: 0.2952 - accuracy: 0.8767 - val_loss: 0.4724 - val_accuracy: 0.8076\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 8s 84ms/step - loss: 0.2789 - accuracy: 0.8805 - val_loss: 0.4780 - val_accuracy: 0.8148\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b17e043f08>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain,validation_data=(xvalid_pad, yvalid), epochs=30 , batch_size=64,callbacks = EarlyStopping(patience=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def roc_auc(predictions,target):\n",
        "    '''\n",
        "    This methods returns the AUC Score when given the Predictions\n",
        "    and Labels\n",
        "    '''\n",
        "    \n",
        "    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n",
        "    roc_auc = metrics.auc(fpr, tpr)\n",
        "    return roc_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ghlr-DeYWsD",
        "outputId": "c8faf8fe-2f3a-4d89-e21f-8ce56df34dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "48/48 [==============================] - 1s 20ms/step\n",
            "Auc: 0.88%\n"
          ]
        }
      ],
      "source": [
        "scores = model.predict(xvalid_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 2s 20ms/step\n"
          ]
        }
      ],
      "source": [
        "#Finally we will predict the test to upload the resuts to kaggle\n",
        "test_predict=model.predict(test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3263, 1)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.6043087 ],\n",
              "       [0.97589767],\n",
              "       [0.9783032 ],\n",
              "       ...,\n",
              "       [0.9922785 ],\n",
              "       [0.80060834],\n",
              "       [0.69054145]], dtype=float32)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We adopt the correct format (1 or 0)\n",
        "test_predict_format=[1 if value[0]>0.5 else 0 for value in test_predict]\n",
        "test_predict_format=np.array(test_predict_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = test_predict_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_LSTM_from_Pretrained_model.csv\",index=False)\n",
        "# We have obtained 0.79068 on Kaggle not improving our best result yet: 0.80049 TF-IDF with Lineal model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sixth approach -GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text.values, train_df.target.values, \n",
        "                                                  stratify=train_df.target.values, \n",
        "                                                  random_state=40, \n",
        "                                                  test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 35 #the maximum value of words (tokens) in the twitts is 33 that's why we set it to 35\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "test_seq=token.texts_to_sequences(test_df.text.values)\n",
        "\n",
        "#zero pad the sequences\n",
        "xtrain_pad = tf.keras.utils.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = tf.keras.utils.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "test_pad = tf.keras.utils.pad_sequences(test_seq, maxlen=max_len)\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 35, 300)           6810300   \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spatia  (None, 35, 300)          0         \n",
            " lDropout1D)                                                     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 300)               541800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 301       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,352,401\n",
            "Trainable params: 542,101\n",
            "Non-trainable params: 6,810,300\n",
            "_________________________________________________________________\n",
            "Wall time: 253 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# GRU with glove embeddings and two dense layers\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                300,\n",
        "                weights=[embedding_matrix],\n",
        "                input_length=max_len,\n",
        "                trainable=False))\n",
        "model.add(SpatialDropout1D(0.3))\n",
        "model.add(GRU(300))\n",
        "model.add(Dense(1, activation='relu'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])   \n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B2A8A1FAF8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B2A8A1FAF8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "95/96 [============================>.] - ETA: 0s - loss: 4.3529 - accuracy: 0.5562WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2A8E56E58> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2A8E56E58> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "96/96 [==============================] - 9s 78ms/step - loss: 4.3516 - accuracy: 0.5563 - val_loss: 1.5722 - val_accuracy: 0.5640\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 8s 83ms/step - loss: 1.8687 - accuracy: 0.5898 - val_loss: 1.6911 - val_accuracy: 0.6290\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 9s 89ms/step - loss: 1.5443 - accuracy: 0.6690 - val_loss: 1.1155 - val_accuracy: 0.7708\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 9s 89ms/step - loss: 1.2605 - accuracy: 0.6800 - val_loss: 0.9308 - val_accuracy: 0.6612\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 9s 91ms/step - loss: 1.2366 - accuracy: 0.6944 - val_loss: 0.8775 - val_accuracy: 0.7019\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 9s 92ms/step - loss: 1.0693 - accuracy: 0.7163 - val_loss: 0.6566 - val_accuracy: 0.7695\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 9s 93ms/step - loss: 0.8175 - accuracy: 0.7250 - val_loss: 0.6066 - val_accuracy: 0.7374\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 9s 95ms/step - loss: 0.6449 - accuracy: 0.7422 - val_loss: 0.5668 - val_accuracy: 0.7794\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 9s 96ms/step - loss: 0.9357 - accuracy: 0.7325 - val_loss: 0.6204 - val_accuracy: 0.7571\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 9s 96ms/step - loss: 0.6076 - accuracy: 0.7568 - val_loss: 0.5743 - val_accuracy: 0.7774\n",
            "Epoch 11/30\n",
            "96/96 [==============================] - 10s 108ms/step - loss: 0.9516 - accuracy: 0.6514 - val_loss: 0.5450 - val_accuracy: 0.7571\n",
            "Epoch 12/30\n",
            "96/96 [==============================] - 11s 113ms/step - loss: 0.5333 - accuracy: 0.7598 - val_loss: 0.4996 - val_accuracy: 0.8043\n",
            "Epoch 13/30\n",
            "96/96 [==============================] - 11s 120ms/step - loss: 0.5367 - accuracy: 0.7706 - val_loss: 0.4869 - val_accuracy: 0.8201\n",
            "Epoch 14/30\n",
            "96/96 [==============================] - 12s 129ms/step - loss: 0.4796 - accuracy: 0.7928 - val_loss: 0.5358 - val_accuracy: 0.8116\n",
            "Epoch 15/30\n",
            "96/96 [==============================] - 14s 142ms/step - loss: 0.4615 - accuracy: 0.7984 - val_loss: 0.5025 - val_accuracy: 0.8109\n",
            "Epoch 16/30\n",
            "96/96 [==============================] - 15s 158ms/step - loss: 0.4654 - accuracy: 0.8072 - val_loss: 0.5099 - val_accuracy: 0.8332\n",
            "Epoch 17/30\n",
            "96/96 [==============================] - 16s 166ms/step - loss: 0.4957 - accuracy: 0.7888 - val_loss: 0.5381 - val_accuracy: 0.8083\n",
            "Epoch 18/30\n",
            "96/96 [==============================] - 16s 165ms/step - loss: 0.4739 - accuracy: 0.8066 - val_loss: 0.4693 - val_accuracy: 0.8116\n",
            "Epoch 19/30\n",
            "96/96 [==============================] - 17s 177ms/step - loss: 0.5085 - accuracy: 0.7913 - val_loss: 0.5003 - val_accuracy: 0.7840\n",
            "Epoch 20/30\n",
            "96/96 [==============================] - 16s 166ms/step - loss: 0.4859 - accuracy: 0.7875 - val_loss: 0.4473 - val_accuracy: 0.8214\n",
            "Epoch 21/30\n",
            "96/96 [==============================] - 15s 160ms/step - loss: 0.4361 - accuracy: 0.8164 - val_loss: 0.5134 - val_accuracy: 0.8286\n",
            "Epoch 22/30\n",
            "96/96 [==============================] - 12s 126ms/step - loss: 0.4370 - accuracy: 0.8210 - val_loss: 0.4627 - val_accuracy: 0.8221\n",
            "Epoch 23/30\n",
            "96/96 [==============================] - 12s 121ms/step - loss: 0.4664 - accuracy: 0.7941 - val_loss: 0.4981 - val_accuracy: 0.8247\n",
            "Epoch 24/30\n",
            "96/96 [==============================] - 12s 125ms/step - loss: 0.4211 - accuracy: 0.8223 - val_loss: 0.5413 - val_accuracy: 0.7853\n",
            "Epoch 25/30\n",
            "96/96 [==============================] - 13s 133ms/step - loss: 0.4066 - accuracy: 0.8238 - val_loss: 0.4974 - val_accuracy: 0.8306\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b2a8aedec8>"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain,validation_data=(xvalid_pad, yvalid), epochs=30 , batch_size=64,callbacks = EarlyStopping(patience=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B2A985E798> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B2A985E798> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "48/48 [==============================] - 1s 23ms/step\n",
            "Auc: 0.89%\n"
          ]
        }
      ],
      "source": [
        "scores = model.predict(xvalid_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 2s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "#Finally we will predict the test to upload the resuts to kaggle\n",
        "test_predict=model.predict(test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We adopt the correct format (1 or 0)\n",
        "test_predict_format=[1 if value[0]>0.5 else 0 for value in test_predict]\n",
        "test_predict_format=np.array(test_predict_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = test_predict_format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_GRU_from_Pretrained_model_relu.csv\",index=False)\n",
        "# We have obtained 0.79926 on Kaggle not improving our best result yet: 0.80049 TF-IDF with Lineal model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Seventh approach - RNN Bi-directional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "xtrain, xvalid, ytrain, yvalid = train_test_split(train_df.text.values, train_df.target.values, \n",
        "                                                  stratify=train_df.target.values, \n",
        "                                                  random_state=40, \n",
        "                                                  test_size=0.2, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "# using keras tokenizer here\n",
        "token = text.Tokenizer(num_words=None)\n",
        "max_len = 35 #the maximum value of words (tokens) in the twitts is 33 that's why we set it to 35\n",
        "\n",
        "token.fit_on_texts(list(xtrain) + list(xvalid))\n",
        "xtrain_seq = token.texts_to_sequences(xtrain)\n",
        "xvalid_seq = token.texts_to_sequences(xvalid)\n",
        "test_seq=token.texts_to_sequences(test_df.text.values)\n",
        "\n",
        "#zero pad the sequences\n",
        "xtrain_pad = tf.keras.utils.pad_sequences(xtrain_seq, maxlen=max_len)\n",
        "xvalid_pad = tf.keras.utils.pad_sequences(xvalid_seq, maxlen=max_len)\n",
        "test_pad = tf.keras.utils.pad_sequences(test_seq, maxlen=max_len)\n",
        "word_index = token.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 35, 300)           6810300   \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 600)              1442400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,253,301\n",
            "Trainable params: 1,443,001\n",
            "Non-trainable params: 6,810,300\n",
            "_________________________________________________________________\n",
            "Wall time: 281 ms\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# A simple bidirectional LSTM with glove embeddings and one dense layer\n",
        "model = Sequential()\n",
        "model.add(Embedding(len(word_index) + 1,\n",
        "                300,\n",
        "                weights=[embedding_matrix],\n",
        "                input_length=max_len,\n",
        "                trainable=False))\n",
        "model.add(Bidirectional(LSTM(300, dropout=0.3, recurrent_dropout=0.3)))\n",
        "\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B2A9A36CA8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x000001B2A9A36CA8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "96/96 [==============================] - ETA: 0s - loss: 0.6208 - accuracy: 0.6644WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2A9EC7708> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x000001B2A9EC7708> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "96/96 [==============================] - 38s 364ms/step - loss: 0.6208 - accuracy: 0.6644 - val_loss: 0.5572 - val_accuracy: 0.7078\n",
            "Epoch 2/30\n",
            "96/96 [==============================] - 38s 395ms/step - loss: 0.5524 - accuracy: 0.7289 - val_loss: 0.5667 - val_accuracy: 0.7190\n",
            "Epoch 3/30\n",
            "96/96 [==============================] - 45s 471ms/step - loss: 0.5311 - accuracy: 0.7361 - val_loss: 0.5217 - val_accuracy: 0.7485\n",
            "Epoch 4/30\n",
            "96/96 [==============================] - 66s 693ms/step - loss: 0.4974 - accuracy: 0.7593 - val_loss: 0.5144 - val_accuracy: 0.7525\n",
            "Epoch 5/30\n",
            "96/96 [==============================] - 72s 750ms/step - loss: 0.4681 - accuracy: 0.7773 - val_loss: 0.5114 - val_accuracy: 0.7557\n",
            "Epoch 6/30\n",
            "96/96 [==============================] - 69s 719ms/step - loss: 0.4367 - accuracy: 0.7941 - val_loss: 0.5163 - val_accuracy: 0.7617\n",
            "Epoch 7/30\n",
            "96/96 [==============================] - 70s 735ms/step - loss: 0.4042 - accuracy: 0.8199 - val_loss: 0.5502 - val_accuracy: 0.7518\n",
            "Epoch 8/30\n",
            "96/96 [==============================] - 61s 641ms/step - loss: 0.3649 - accuracy: 0.8402 - val_loss: 0.5637 - val_accuracy: 0.7492\n",
            "Epoch 9/30\n",
            "96/96 [==============================] - 56s 579ms/step - loss: 0.3282 - accuracy: 0.8612 - val_loss: 0.5439 - val_accuracy: 0.7656\n",
            "Epoch 10/30\n",
            "96/96 [==============================] - 64s 672ms/step - loss: 0.2878 - accuracy: 0.8796 - val_loss: 0.6664 - val_accuracy: 0.7347\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b29b096448>"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(xtrain_pad, ytrain,validation_data=(xvalid_pad, yvalid), epochs=30 , batch_size=64,callbacks = EarlyStopping(patience=5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B2A175D8B8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B2A175D8B8> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "48/48 [==============================] - 4s 81ms/step\n",
            "Auc: 0.80%\n"
          ]
        }
      ],
      "source": [
        "scores = model.predict(xvalid_pad)\n",
        "print(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "102/102 [==============================] - 9s 84ms/step\n"
          ]
        }
      ],
      "source": [
        "#Finally we will predict the test to upload the resuts to kaggle\n",
        "test_predict=model.predict(test_pad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We adopt the correct format (1 or 0)\n",
        "test_predict_format=[1 if value[0]>0.5 else 0 for value in test_predict]\n",
        "test_predict_format=np.array(test_predict_format)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3258</th>\n",
              "      <td>10861</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3259</th>\n",
              "      <td>10865</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3260</th>\n",
              "      <td>10868</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3261</th>\n",
              "      <td>10874</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>10875</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3263 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  target\n",
              "0         0       0\n",
              "1         2       1\n",
              "2         3       1\n",
              "3         9       0\n",
              "4        11       1\n",
              "...     ...     ...\n",
              "3258  10861       1\n",
              "3259  10865       1\n",
              "3260  10868       1\n",
              "3261  10874       1\n",
              "3262  10875       0\n",
              "\n",
              "[3263 rows x 2 columns]"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_submission = pd.read_csv(\"sample_submission.csv\")\n",
        "sample_submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission[\"target\"] = test_predict_format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_submission.to_csv(\"sample_submission_RNN_Bi-directional_from_Pretrained_model_sigmoid.csv\",index=False)\n",
        "# We have obtained 0.69138 on Kaggle not improving our best result yet: 0.80049 TF-IDF with Lineal model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.7.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "50bb62f541a8ae06967793983095c4bc1944cb2fcd2d01adf648b719ed81bce2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
